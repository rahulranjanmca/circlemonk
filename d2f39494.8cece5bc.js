(window.webpackJsonp=window.webpackJsonp||[]).push([[156],{297:function(e,a,t){"use strict";t.r(a),t.d(a,"frontMatter",(function(){return r})),t.d(a,"rightToc",(function(){return s})),t.d(a,"default",(function(){return c}));t(0);var o=t(329);function i(){return(i=Object.assign||function(e){for(var a=1;a<arguments.length;a++){var t=arguments[a];for(var o in t)Object.prototype.hasOwnProperty.call(t,o)&&(e[o]=t[o])}return e}).apply(this,arguments)}const r={id:"start",title:"Kafka Interview Questions",sidebar_label:"Basics"},s=[{value:"What is Apache Kafka?",id:"what-is-apache-kafka",children:[]},{value:"Enlist the several components in Kafka.",id:"enlist-the-several-components-in-kafka",children:[]},{value:"Explain the role of the offset.",id:"explain-the-role-of-the-offset",children:[]},{value:"What is a Consumer Group?",id:"what-is-a-consumer-group",children:[]},{value:"What is the role of the ZooKeeper in Kafka?",id:"what-is-the-role-of-the-zookeeper-in-kafka",children:[]},{value:"Is it possible to use Kafka without ZooKeeper?",id:"is-it-possible-to-use-kafka-without-zookeeper",children:[]},{value:"What do you know about Partition in Kafka?",id:"what-do-you-know-about-partition-in-kafka",children:[]},{value:"Why is Kafka technology significant to use?",id:"why-is-kafka-technology-significant-to-use",children:[]},{value:"What are main APIs of Kafka?",id:"what-are-main-apis-of-kafka",children:[]},{value:"What are consumers or users?",id:"what-are-consumers-or-users",children:[]},{value:"Explain the concept of Leader and Follower.",id:"explain-the-concept-of-leader-and-follower",children:[]},{value:"What ensures load balancing of the server in Kafka?",id:"what-ensures-load-balancing-of-the-server-in-kafka",children:[]},{value:"What roles do Replicas and the ISR play?",id:"what-roles-do-replicas-and-the-isr-play",children:[]},{value:"Why are Replications critical in Kafka?",id:"why-are-replications-critical-in-kafka",children:[]},{value:"If a Replica stays out of the ISR for a long time, what does it signify?",id:"if-a-replica-stays-out-of-the-isr-for-a-long-time-what-does-it-signify",children:[]},{value:"What is the process for starting a Kafka server?",id:"what-is-the-process-for-starting-a-kafka-server",children:[]},{value:"In the Producer, when does QueueFullException occur?",id:"in-the-producer-when-does-queuefullexception-occur",children:[]},{value:"Explain the role of the Kafka Producer API.",id:"explain-the-role-of-the-kafka-producer-api",children:[]},{value:"Is Apache Kafka is a distributed streaming platform? if yes, what you can do with it?",id:"is-apache-kafka-is-a-distributed-streaming-platform-if-yes-what-you-can-do-with-it",children:[]},{value:"Moreover, it can process the records as they come in",id:"moreover-it-can-process-the-records-as-they-come-in",children:[{value:"What can you do with Kafka?",id:"what-can-you-do-with-kafka",children:[]},{value:"What is the purpose of retention period in Kafka cluster?",id:"what-is-the-purpose-of-retention-period-in-kafka-cluster",children:[]},{value:"Explain the maximum size of a message that can be received by the Kafka?",id:"explain-the-maximum-size-of-a-message-that-can-be-received-by-the-kafka",children:[]},{value:"What are the types of traditional method of message transfer?",id:"what-are-the-types-of-traditional-method-of-message-transfer",children:[]},{value:"What does ISR stand in Kafka environment?",id:"what-does-isr-stand-in-kafka-environment",children:[]},{value:"What is Geo-Replication in Kafka?",id:"what-is-geo-replication-in-kafka",children:[]},{value:"What is the role of Consumer API?",id:"what-is-the-role-of-consumer-api",children:[]},{value:"Explain the role of Streams API?",id:"explain-the-role-of-streams-api",children:[]},{value:"What is the role of Connector API?",id:"what-is-the-role-of-connector-api",children:[]},{value:"Explain Producer?",id:"explain-producer",children:[]},{value:"Compare: RabbitMQ vs Apache Kafka",id:"compare-rabbitmq-vs-apache-kafka",children:[]},{value:"Compare: Traditional queuing systems vs Apache Kafka",id:"compare-traditional-queuing-systems-vs-apache-kafka",children:[]},{value:"Why Should we use Apache Kafka Cluster?",id:"why-should-we-use-apache-kafka-cluster",children:[]},{value:"Explain the term 'Log Anatomy'.",id:"explain-the-term-log-anatomy",children:[]},{value:"What is Data Log in Kafka?",id:"what-is-data-log-in-kafka",children:[]},{value:"Explain how to Tune Kafka for Optimal Performance.",id:"explain-how-to-tune-kafka-for-optimal-performance",children:[]},{value:"State Disadvantages of Apache Kafka.",id:"state-disadvantages-of-apache-kafka",children:[]},{value:"Enlist all Apache Kafka Operations.",id:"enlist-all-apache-kafka-operations",children:[]},{value:"Explain Apache Kafka Use Cases?",id:"explain-apache-kafka-use-cases",children:[]},{value:"Some of the most notable applications of Kafka.",id:"some-of-the-most-notable-applications-of-kafka",children:[]},{value:"Features of Kafka Stream.",id:"features-of-kafka-stream",children:[]},{value:"What do you mean by Stream Processing in Kafka?",id:"what-do-you-mean-by-stream-processing-in-kafka",children:[]},{value:"What are the types of System tools?",id:"what-are-the-types-of-system-tools",children:[]},{value:"What are Replication Tool and its types?",id:"what-are-replication-tool-and-its-types",children:[]},{value:"What is Importance of Java in Apache Kafka?",id:"what-is-importance-of-java-in-apache-kafka",children:[]},{value:"State one best feature of Kafka.",id:"state-one-best-feature-of-kafka",children:[]},{value:"Explain the term \u201cTopic Replication Factor\u201d.",id:"explain-the-term-topic-replication-factor",children:[]},{value:"Explain some Kafka Streams real-time Use Cases.",id:"explain-some-kafka-streams-real-time-use-cases",children:[]},{value:"What are Guarantees provided by Kafka?",id:"what-are-guarantees-provided-by-kafka",children:[]}]}],n={rightToc:s},l="wrapper";function c({components:e,...a}){return Object(o.b)(l,i({},n,a,{components:e,mdxType:"MDXLayout"}),Object(o.b)("h3",{id:"what-is-apache-kafka"},"What is Apache Kafka?"),Object(o.b)("p",null,"Apache Kafka is a publish-subscribe open source message broker application. This messaging application was coded in ",Object(o.b)("inlineCode",{parentName:"p"},"Scala"),". Basically, this project was started by the Apache software. Kafka's design pattern is mainly based on the transactional logs design."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"enlist-the-several-components-in-kafka"},"Enlist the several components in Kafka."),Object(o.b)("p",null,"The most important elements of Kafka are:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Topic \u2013\nKafka Topic is the bunch or a collection of messages.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Producer \u2013\nIn Kafka, Producers issue communications as well as publishes messages to a Kafka topic.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Consumer \u2013\nKafka Consumers subscribes to a topic(s) and also reads and processes messages from the topic(s).")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Brokers \u2013\nWhile it comes to manage storage of messages in the topic(s) we use Kafka Brokers."))),Object(o.b)("hr",null),Object(o.b)("h3",{id:"explain-the-role-of-the-offset"},"Explain the role of the offset."),Object(o.b)("p",null,"There is a sequential ID number given to the messages in the partitions what we call, an offset. So, to identify each message in the partition uniquely, we use these offsets."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-is-a-consumer-group"},"What is a Consumer Group?"),Object(o.b)("p",null," The concept of Consumer Groups is exclusive to Apache Kafka. Basically, every Kafka consumer group consists of one or more consumers that jointly consume a set of subscribed topics."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-is-the-role-of-the-zookeeper-in-kafka"},"What is the role of the ZooKeeper in Kafka?"),Object(o.b)("p",null," Apache Kafka is a distributed system is built to use Zookeeper. Although, Zookeeper\u2019s main role here is to build coordination between different nodes in a cluster. However, we also use Zookeeper to recover from previously committed offset if any node fails because it works as periodically commit offset."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"is-it-possible-to-use-kafka-without-zookeeper"},"Is it possible to use Kafka without ZooKeeper?"),Object(o.b)("p",null," It is impossible to bypass Zookeeper and connect directly to the Kafka server, so the answer is no. If somehow, ZooKeeper is down, then it is impossible to service any client request."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-do-you-know-about-partition-in-kafka"},"What do you know about Partition in Kafka?"),Object(o.b)("p",null,"In every Kafka broker, there are few partitions available. And, here each partition in Kafka can be either a leader or a replica of a topic."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"why-is-kafka-technology-significant-to-use"},"Why is Kafka technology significant to use?"),Object(o.b)("p",null,"There are some advantages of Kafka, which makes it significant to use:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},Object(o.b)("strong",{parentName:"p"},"High-throughput"),":\nWe do not need any large hardware in Kafka, because it is capable of handling high-velocity and high-volume data. Moreover, it can also support message throughput of thousands of messages per second.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},Object(o.b)("strong",{parentName:"p"},"Low Latency"),":\nKafka can easily handle these messages with the very low latency of the range of milliseconds, demanded by most of the new use cases.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},Object(o.b)("strong",{parentName:"p"},"Fault-Tolerant"),":\nKafka is resistant to node/machine failure within a cluster.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},Object(o.b)("strong",{parentName:"p"},"Durability"),":\nAs Kafka supports messages replication, so, messages are never lost. It is one of the reasons behind durability.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},Object(o.b)("strong",{parentName:"p"},"Scalability"),":\nKafka can be scaled-out, without incurring any downtime on the fly by adding additional nodes."))),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-are-main-apis-of-kafka"},"What are main APIs of Kafka?"),Object(o.b)("p",null,"Ans. Apache Kafka has 4 main APIs:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Producer API"),Object(o.b)("li",{parentName:"ul"},"Consumer API"),Object(o.b)("li",{parentName:"ul"},"Streams API"),Object(o.b)("li",{parentName:"ul"},"Connector API")),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-are-consumers-or-users"},"What are consumers or users?"),Object(o.b)("p",null," Mainly, Kafka Consumer subscribes to a topic(s), and also reads and processes messages from the topic(s). Moreover, with a consumer group name, Consumers label themselves. In other words, within each subscribing consumer group, each record published to a topic is delivered to one consumer instance. Make sure it is possible that Consumer instances can be in separate processes or on separate machines."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"explain-the-concept-of-leader-and-follower"},"Explain the concept of Leader and Follower."),Object(o.b)("p",null,"In every partition of Kafka, there is one server which acts as the Leader, and none or more servers plays the role as a Followers."),Object(o.b)("h3",{id:"what-ensures-load-balancing-of-the-server-in-kafka"},"What ensures load balancing of the server in Kafka?"),Object(o.b)("p",null,"As the main role of the Leader is to perform the task of all read and write requests for the partition, whereas Followers passively replicate the leader. Hence, at the time of Leader failing, one of the Followers takeover the role of the Leader. Basically, this entire process ensures load balancing of the servers."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-roles-do-replicas-and-the-isr-play"},"What roles do Replicas and the ISR play?"),Object(o.b)("p",null,"Basically, a list of nodes that replicate the log is Replicas. Especially, for a particular partition. However, they are irrespective of whether they play the role of the Leader.\nIn addition, ISR refers to In-Sync Replicas. On defining ISR, it is a set of message replicas that are synced to the leaders."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"why-are-replications-critical-in-kafka"},"Why are Replications critical in Kafka?"),Object(o.b)("p",null,"Because of Replication, we can be sure that published messages are not lost and can be consumed in the event of any machine error, program error or frequent software upgrades."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"if-a-replica-stays-out-of-the-isr-for-a-long-time-what-does-it-signify"},"If a Replica stays out of the ISR for a long time, what does it signify?"),Object(o.b)("p",null,"Simply, it implies that the Follower cannot fetch data as fast as data accumulated by the Leader."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-is-the-process-for-starting-a-kafka-server"},"What is the process for starting a Kafka server?"),Object(o.b)("p",null,"Ans. It is the very important step to initialize the ZooKeeper server because Kafka uses ZooKeeper.So, the process for starting a Kafka server is:\nIn order to start the ZooKeeper server: "),Object(o.b)("pre",null,Object(o.b)("code",i({parentName:"pre"},{className:"language-bash"}),"$ bin/zookeeper-server-start.sh config/zookeeper.properties\n")),Object(o.b)("p",null,"Next, to start the Kafka server: "),Object(o.b)("pre",null,Object(o.b)("code",i({parentName:"pre"},{className:"language-bash"}),"$ bin/kafka-server-start.sh config/server.properties\n")),Object(o.b)("hr",null),Object(o.b)("h3",{id:"in-the-producer-when-does-queuefullexception-occur"},"In the Producer, when does QueueFullException occur?"),Object(o.b)("p",null,"Whenever the Kafka Producer attempts to send messages at a pace that the Broker cannot handle at that time QueueFullException typically occurs. However, to collaboratively handle the increased load, users will need to add enough brokers, since the Producer doesn\u2019t block."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"explain-the-role-of-the-kafka-producer-api"},"Explain the role of the Kafka Producer API."),Object(o.b)("p",null,"An API which permits an application to publish a stream of records to one or more Kafka topics is what we call Producer API."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"is-apache-kafka-is-a-distributed-streaming-platform-if-yes-what-you-can-do-with-it"},"Is Apache Kafka is a distributed streaming platform? if yes, what you can do with it?"),Object(o.b)("p",null,"Undoubtedly, Kafka is a streaming platform. It can help:"),Object(o.b)("p",null,"To push records easily\nAlso, can store a lot of records without giving any storage problems"),Object(o.b)("h2",{id:"moreover-it-can-process-the-records-as-they-come-in"},"Moreover, it can process the records as they come in"),Object(o.b)("h3",{id:"what-can-you-do-with-kafka"},"What can you do with Kafka?"),Object(o.b)("p",null,"It can perform in several ways, such as:"),Object(o.b)("p",null,"In order to transmit data between two systems, we can build a real-time stream of data pipelines with it."),Object(o.b)("p",null,"Also, we can build a real-time streaming platform with Kafka, that can actually react to the data."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-is-the-purpose-of-retention-period-in-kafka-cluster"},"What is the purpose of retention period in Kafka cluster?"),Object(o.b)("p",null,"Retention period refers to time for which it retains all the published records within the Kafka cluster. It doesn\u2019t check whether they have been consumed or not. Moreover, the records can be discarded by using a configuration setting for the retention period. And, it results as it can free up some space."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"explain-the-maximum-size-of-a-message-that-can-be-received-by-the-kafka"},"Explain the maximum size of a message that can be received by the Kafka?"),Object(o.b)("p",null,"The maximum size of a message that can be received by the Kafka is approx. 1000000 bytes."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-are-the-types-of-traditional-method-of-message-transfer"},"What are the types of traditional method of message transfer?"),Object(o.b)("p",null," Basically, there are two methods of the traditional message transfer method, such as:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"Queuing"),": It is a method in which a pool of consumers may read a message from the server and each message goes to one of them."),Object(o.b)("li",{parentName:"ul"},Object(o.b)("strong",{parentName:"li"},"Publish-Subscribe"),": Whereas in Publish-Subscribe, messages are broadcasted to all consumers.")),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-does-isr-stand-in-kafka-environment"},"What does ISR stand in Kafka environment?"),Object(o.b)("p",null,"ISR refers to ",Object(o.b)("inlineCode",{parentName:"p"},"In Sync Replicas"),". These are generally classified as a set of message replicas which are synced to be leaders."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-is-geo-replication-in-kafka"},"What is Geo-Replication in Kafka?"),Object(o.b)("p",null,"For our cluster, Kafka MirrorMaker offers geo-replication. Basically, messages are replicated across multiple data centers or cloud regions, with MirrorMaker. So, it can be used in active/passive scenarios for backup and recovery; or also to place data closer to our users, or support data locality requirements."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-is-the-role-of-consumer-api"},"What is the role of Consumer API?"),Object(o.b)("p",null,"An API which permits an application to subscribe to one or more topics and also to process the stream of records produced to them is what we call Consumer API."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"explain-the-role-of-streams-api"},"Explain the role of Streams API?"),Object(o.b)("p",null,"An API which permits an application to act as a stream processor, and also consuming an input stream from one or more topics and producing an output stream to one or more output topics, moreover, transforming the input streams to output streams effectively, is what we call Streams API."),Object(o.b)("h3",{id:"what-is-the-role-of-connector-api"},"What is the role of Connector API?"),Object(o.b)("p",null,"Ans. An API which permits to run as well as build the reusable producers or consumers which connect Kafka topics to existing applications or data systems is what we call the Connector API."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"explain-producer"},"Explain Producer?"),Object(o.b)("p",null,"The main role of Producers is to publish data to the topics of their choice. Basically, its duty is to select the record to assign to partition within the topic."),Object(o.b)("h3",{id:"compare-rabbitmq-vs-apache-kafka"},"Compare: RabbitMQ vs Apache Kafka"),Object(o.b)("p",null,"One of the Apache Kafka\u2019s alternative is RabbitMQ. So, let\u2019s compare both:\n1. Features"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Apache Kafka\u2013 Kafka is distributed, durable and highly available, here the data is shared as well as replicated."),Object(o.b)("li",{parentName:"ul"},"RabbitMQ\u2013 There are no such features in RabbitMQ.")),Object(o.b)("ol",{start:2},Object(o.b)("li",{parentName:"ol"},"Performance rate",Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"Apache Kafka\u2013 To the tune of 100,000 messages/second."),Object(o.b)("li",{parentName:"ul"},"RabbitMQ- In case of RabbitMQ, the performance rate is around 20,000 messages/second.")))),Object(o.b)("hr",null),Object(o.b)("h3",{id:"compare-traditional-queuing-systems-vs-apache-kafka"},"Compare: Traditional queuing systems vs Apache Kafka"),Object(o.b)("p",null," Let\u2019s compare Traditional queuing systems vs Apache Kafka feature-wise:"),Object(o.b)("ol",null,Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Messages Retaining"),Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"Traditional queuing systems\u2013 It deletes the messages just after processing completion typically from the end of the queue."),Object(o.b)("li",{parentName:"ul"},"Apache Kafka\u2013 But in Kafka, messages persist even after being processed. That implies messages in Kafka don\u2019t get removed as consumers receive them."))),Object(o.b)("li",{parentName:"ol"},Object(o.b)("p",{parentName:"li"},"Logic-based processing"),Object(o.b)("ul",{parentName:"li"},Object(o.b)("li",{parentName:"ul"},"Traditional queuing systems\u2013Traditional queuing systems don\u2019t permit to process logic based on similar messages or events."),Object(o.b)("li",{parentName:"ul"},"Apache Kafka\u2013 Kafka permits to process logic based on similar messages or events.")))),Object(o.b)("hr",null),Object(o.b)("h3",{id:"why-should-we-use-apache-kafka-cluster"},"Why Should we use Apache Kafka Cluster?"),Object(o.b)("p",null,"In order to overcome the challenges of collecting the large volume of data, and analyzing the collected data we need a messaging system. Hence Apache Kafka came in the story. Its benefits are:"),Object(o.b)("p",null,"It is possible to track web activities just by storing/sending the events for real-time processes.\nThrough this, we can Alert as well as report the operational metrics.\nAlso, we can transform data into the standard format.\nMoreover, it allows continuous processing of streaming data to the topics.\nDue to its this wide use, it is ruling over some of the most popular applications like ActiveMQ, RabbitMQ, AWS etc."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"explain-the-term-log-anatomy"},"Explain the term 'Log Anatomy'."),Object(o.b)("p",null,"We view log as the partitions. Basically, a data source writes messages to the log. One of the advantages is, at any time one or more consumers read from the log they select. Here, below diagram shows a log is being written by the data source and the log is being read by consumers at different offsets."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-is-data-log-in-kafka"},"What is Data Log in Kafka?"),Object(o.b)("p",null,"As we know, messages are retained for a considerable amount of time in Kafka. Moreover, there is flexibility for consumers that they can read as per their convenience. Although, there is a possible case that if Kafka is configured to keep messages for 24 hours and possibly that time consumer is down for time greater than 24 hours, then the consumer may lose those messages. However, still, we can read those messages from last known offset, but only at a condition that the downtime on part of the consumer is just 60 minutes. Moreover, on what consumers are reading from a topic Kafka doesn\u2019t keep state."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"explain-how-to-tune-kafka-for-optimal-performance"},"Explain how to Tune Kafka for Optimal Performance."),Object(o.b)("p",null,"So, ways to tune Apache Kafka it is to tune its several components:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Tuning Kafka Producers"),Object(o.b)("li",{parentName:"ul"},"Kafka Brokers Tuning "),Object(o.b)("li",{parentName:"ul"},"Tuning Kafka Consumers")),Object(o.b)("hr",null),Object(o.b)("h3",{id:"state-disadvantages-of-apache-kafka"},"State Disadvantages of Apache Kafka."),Object(o.b)("p",null,"Ans. Limitations of Kafka are:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"No Complete Set of Monitoring Tools"),Object(o.b)("li",{parentName:"ul"},"Issues with Message Tweaking"),Object(o.b)("li",{parentName:"ul"},"Not support wildcard topic selection"),Object(o.b)("li",{parentName:"ul"},"Lack of Pace")),Object(o.b)("hr",null),Object(o.b)("h3",{id:"enlist-all-apache-kafka-operations"},"Enlist all Apache Kafka Operations."),Object(o.b)("p",null,"Apache Kafka Operations are:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Addition and Deletion of Kafka Topics"),Object(o.b)("li",{parentName:"ul"},"How to modify the Kafka Topics"),Object(o.b)("li",{parentName:"ul"},"Distinguished Turnoff"),Object(o.b)("li",{parentName:"ul"},"Mirroring Data between Kafka Clusters"),Object(o.b)("li",{parentName:"ul"},"Finding the position of the Consumer"),Object(o.b)("li",{parentName:"ul"},"Expanding Your Kafka Cluster"),Object(o.b)("li",{parentName:"ul"},"Migration of Data Automatically"),Object(o.b)("li",{parentName:"ul"},"Retiring Servers"),Object(o.b)("li",{parentName:"ul"},"Datacenters")),Object(o.b)("hr",null),Object(o.b)("h3",{id:"explain-apache-kafka-use-cases"},"Explain Apache Kafka Use Cases?"),Object(o.b)("p",null," Apache Kafka has so many use cases, such as:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Kafka Metrics\nIt is possible to use Kafka for operational monitoring data. Also, to produce centralized feeds of operational data, it involves aggregating statistics from distributed applications.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Kafka Log Aggregation\nMoreover, to gather logs from multiple services across an organization.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},"Stream Processing\nWhile stream processing, Kafka\u2019s strong durability is very useful."))),Object(o.b)("hr",null),Object(o.b)("h3",{id:"some-of-the-most-notable-applications-of-kafka"},"Some of the most notable applications of Kafka."),Object(o.b)("p",null,"Ans. Some of the real-time applications are:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Netflix"),Object(o.b)("li",{parentName:"ul"},"Mozilla"),Object(o.b)("li",{parentName:"ul"},"Oracle\nLearn more and detailed applications in detail, follow the link Kafka \u2013 Applications")),Object(o.b)("h3",{id:"features-of-kafka-stream"},"Features of Kafka Stream."),Object(o.b)("p",null,"Ans. Some best features of Kafka Stream are"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Kafka Streams are highly scalable and fault-tolerant."),Object(o.b)("li",{parentName:"ul"},"Kafka deploys to containers, VMs, bare metal, cloud."),Object(o.b)("li",{parentName:"ul"},"We can say, Kafka streams are equally viable for small, medium, & large use cases."),Object(o.b)("li",{parentName:"ul"},"Also, it is fully in integration with Kafka security."),Object(o.b)("li",{parentName:"ul"},"Write standard Java applications."),Object(o.b)("li",{parentName:"ul"},"Exactly-once processing semantics."),Object(o.b)("li",{parentName:"ul"},"Moreover, there is no need of separate processing cluster.")),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-do-you-mean-by-stream-processing-in-kafka"},"What do you mean by Stream Processing in Kafka?"),Object(o.b)("p",null,"The type of processing of data continuously, real-time,  concurrently, and in a record-by-record fashion is what we call Kafka Stream processing."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-are-the-types-of-system-tools"},"What are the types of System tools?"),Object(o.b)("p",null,"There are three types of System tools:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},Object(o.b)("strong",{parentName:"p"},"Kafka Migration Tool"),":\nIt helps to migrate a broker from one version to another.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},Object(o.b)("strong",{parentName:"p"},"Mirror Maker"),":\nMirror Maker tool helps to offer to mirror of one Kafka cluster to another.")),Object(o.b)("li",{parentName:"ul"},Object(o.b)("p",{parentName:"li"},Object(o.b)("strong",{parentName:"p"},"Consumer Offset Checker"),":\nFor the specified set of Topics as well as Consumer Group, it shows Topic, Partitions, Owner."))),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-are-replication-tool-and-its-types"},"What are Replication Tool and its types?"),Object(o.b)("p",null,"Ans. For the purpose of stronger durability and higher availability,  replication tool is available here. Its types are \u2212"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Create Topic Tool"),Object(o.b)("li",{parentName:"ul"},"List Topic Tool"),Object(o.b)("li",{parentName:"ul"},"Add Partition Tool")),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-is-importance-of-java-in-apache-kafka"},"What is Importance of Java in Apache Kafka?"),Object(o.b)("p",null,"For the need of the high processing rates that come standard on Kafka, we can use java language. Moreover, for Kafka consumer clients also, Java offers a good community support. So, we can say it is a right choice to implement Kafka in Java."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"state-one-best-feature-of-kafka"},"State one best feature of Kafka."),Object(o.b)("p",null,"The best feature of Kafka is \u201cVariety of Use Cases\u201d.\nIt means Kafka is able to manage the variety of use cases which are very common for a Data Lake. For Example log aggregation, web activity tracking, and so on."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"explain-the-term-topic-replication-factor"},"Explain the term \u201cTopic Replication Factor\u201d."),Object(o.b)("p",null,"It is very important to factor in topic replication while designing a Kafka system. Hence, if in any case, broker goes down its topics\u2019 replicas from another broker can solve the crisis."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"explain-some-kafka-streams-real-time-use-cases"},"Explain some Kafka Streams real-time Use Cases."),Object(o.b)("p",null,"So, the use cases are:"),Object(o.b)("p",null,"The New York Times\nThis company uses it to store and distribute, in real-time, published content to the various applications and systems that make it available to the readers. Basically, it uses Apache Kafka and the Kafka Streams both."),Object(o.b)("p",null,"Zalando\nAs an ESB (Enterprise Service Bus) as the leading online fashion retailer in Europe Zalando uses Kafka."),Object(o.b)("p",null,"LINE\nBasically, to communicate to one another LINE application uses Apache Kafka as a central data hub for their services."),Object(o.b)("hr",null),Object(o.b)("h3",{id:"what-are-guarantees-provided-by-kafka"},"What are Guarantees provided by Kafka?"),Object(o.b)("p",null,"They are:"),Object(o.b)("p",null,"The order will be same for both the Messages sent by a producer to a particular topic partition. That\nMoreover, the consumer instance sees records in the order in which they are stored in the log.\nAlso, we can tolerate up to N-1 server failures, even without losing any records committed to the log."))}c.isMDXComponent=!0},329:function(e,a,t){"use strict";t.d(a,"a",(function(){return n})),t.d(a,"b",(function(){return p}));var o=t(0),i=t.n(o),r=i.a.createContext({}),s=function(e){var a=i.a.useContext(r),t=a;return e&&(t="function"==typeof e?e(a):Object.assign({},a,e)),t},n=function(e){var a=s(e.components);return i.a.createElement(r.Provider,{value:a},e.children)};var l="mdxType",c={inlineCode:"code",wrapper:function(e){var a=e.children;return i.a.createElement(i.a.Fragment,{},a)}},h=Object(o.forwardRef)((function(e,a){var t=e.components,o=e.mdxType,r=e.originalType,n=e.parentName,l=function(e,a){var t={};for(var o in e)Object.prototype.hasOwnProperty.call(e,o)&&-1===a.indexOf(o)&&(t[o]=e[o]);return t}(e,["components","mdxType","originalType","parentName"]),h=s(t),p=o,b=h[n+"."+p]||h[p]||c[p]||r;return t?i.a.createElement(b,Object.assign({},{ref:a},l,{components:t})):i.a.createElement(b,Object.assign({},{ref:a},l))}));function p(e,a){var t=arguments,o=a&&a.mdxType;if("string"==typeof e||o){var r=t.length,s=new Array(r);s[0]=h;var n={};for(var c in a)hasOwnProperty.call(a,c)&&(n[c]=a[c]);n.originalType=e,n[l]="string"==typeof e?e:o,s[1]=n;for(var p=2;p<r;p++)s[p]=t[p];return i.a.createElement.apply(null,s)}return i.a.createElement.apply(null,t)}h.displayName="MDXCreateElement"}}]);